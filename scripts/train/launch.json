{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python:train",
            "type": "python",
            "request": "launch",
            "pythonPath": "/workdir/conda_envs/tyllava/bin/python",
            "program": "./tinyllava/train/train.py",
            "console": "integratedTerminal",
            "args": ["--data_path", "/mnt/data/for_tllava/TinyLlava_text/blip_laion_cc_sbu_558k.json",
            "--image_folder", "/mnt/data/llava/dataset/llava/llava_pretrain",
            "--is_multimodal", "True",
            "--conv_version", "pretrain",
            "--model_name_or_path", "/mnt/weight/HuggingFace/TinyLlama-1.1B-Chat-v1.0",
            "--vision_tower", "/mnt/weight/HuggingFace/google-siglip-so400m-patch14-384",
            "--vision_tower2", "",
            "--connector_type", "mlp2x_gelu",
            "--mm_vision_select_layer", "-2",
            "--image_aspect_ratio", "square",
            "--attn_implementation", "flash_attention_2",
            "--fp16", "True",
            "--training_recipe", "common",
            "--tune_type_llm", "part",
            "--tune_type_vision_tower", "frozen",
            "--tune_vision_tower_from_layer", "0",
            "--tune_type_connector", "full",
            "--output_dir", "/mnt/weight/checkpoints/llava_factory_TestOnly/04-test2_tllava-TinyLlama-1.1B-Chat-v1.0-siglip-so400m-patch14-384-base_M3-04-pretrain_fa",
            "--num_train_epochs", "1",
            "--per_device_train_batch_size", "32",
            "--per_device_eval_batch_size", "4",
            "--gradient_accumulation_steps", "2",
            "--evaluation_strategy", "no",
            "--save_strategy", "steps",
            "--save_steps", "20",
            "--save_total_limit", "1",
            "--learning_rate", "1e-3",
            "--weight_decay", "0.",
            "--warmup_ratio", "0.03",
            "--lr_scheduler_type", "cosine",
            "--logging_steps", "1",
            "--tf32", "False",
            "--model_max_length", "3072",
            "--gradient_checkpointing", "True",
            "--dataloader_num_workers", "8",
            "--lazy_preprocess", "True",
            "--report_to", "tensorboard",
            "--tokenizer_use_fast", "False",
            "--run_name", "tllava-TinyLlama-1.1B-Chat-v1.0-siglip-so400m-patch14-384-base_M3-04"
          ],
            "justMyCode": false
        },
        {
            "command": "run ${file}",
            "name": "Run Hope",
            "request": "launch",
            "type": "node-terminal"
        }
    ]
}